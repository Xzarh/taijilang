{str, hasOwnProperty, firstIdentifierCharSet, identifierCharSet, firstSymbolCharset, taijiIdentifierCharSet, constant, trace} = require '../utils'

{NULL, NUMBER,  STRING,  IDENTIFIER, SYMBOL, REGEXP, PUNCTUATION
PAREN, BRACKET, CURVE,  NEWLINE,  SPACES
LINE_COMMENT, EOI, INDENT, UNDENT, HALF_DENT, SPACE_COMMENT, TAIL_COMMENT
SPACE, RIGHT_DELIMITER, KEYWORD, CONJUNCTION, PREFIX, SUFFIX, BINARY
COMPACT_CLAUSE_EXPRESSION
} = constant

{prefixOperatorDict, binaryOperatorDict} = require './operator'

exports.keywordMap = keywordMap = {'if': 1, 'try':1, 'while':1, 'return':1, 'break':1, 'continue':1, 'throw':1,'for':1, 'var':1}
keywordHasOwnProperty = hasOwnProperty.bind(exports.keywordMap)

exports.conjMap = conjMap = {'then':1, 'else':1, 'catch':1, 'finally':1, 'case':1, 'default':1, 'extends': 1}
conjunctionHasOwnProperty = hasOwnProperty.bind(exports.conjMap)

begin = (exps) ->
  if not exps then return  'undefined'
  else if exps.length==0 then  'undefined'
  else if exps.length==1 then exps[0]
  else
    result = ['begin!']
    for exp in exps
      if exp[0]=='begin!' then result.push.apply exps[1...]
      else result.push exp
    result

exports.Parser = ->
  parser = @

  # global variable used by lexer
  text = '' # text to be parsed
  textLength = text.length;
  cursor = 0 # position pointer while do lexical parsing, use cur for local position pointer
  char = '' # current character, should assure char is the value of text[cursor] whenerver entering or leaving a function
  lineno = 0 # current line number, use line for local line number
  lineStart = 0 # start cursor of current line
  lexIndent = 0 # global lexical indent column of current line, use dent for local indent column
  indent = 0 # global indent while parsing, get from tokens including SPACE, NEWLINE, INDENT, UNDENT, EOI

  # token should have the field: type, value, cursor, stopCursor, line, column
  # token like SPACE, NEWLINE, INDENT, UNDENT should have the field "indent" which means the indent of the end line of the token
  token = undefined # global token generated by lexical parsing and used by the parser
  tokenType = undefined # global current token.type, set in nextToken, matchToken or tokenOnXXX

  # global variable used by the syntax parser
  atStatementHead = true # whether is at head of statement

  eoi = {type:EOI, value:'', cursor: text.length, column: -1, lexIndent:-1, indent: -1} # line wait to be filled
  eoi.next = eoi  # eoi.next is always itself

  # nextToken can do more things, like set global tokenType, tokenValue, etc, atStatementHead
  nextToken = ->
    if token.indent!=undefined then indent = token.indent
    switch tokenType
      when NEWLINE, INDENT, UNDENT, EOI then atStatementHead = true
    if token.next then token = token.next; tokenType = token.type
    else matchToken()

  # tokenFnMap[char](char) and tokenOnSymbolChar should change the token
  # matchToken() should be called by nextToken(with the expanded inline form for the performance)
  # ONLY call matchToken() when after know the cursor and char, or changing cursor and char immediately.
  @matchToken = matchToken = ->
    if fn = tokenFnMap[char] then return token=fn(char)
    else if not char
      if token==eoi then return eoi
      eoi.lineno = lineno+1; token.next = eoi; lineStart = cursor
      return setToken eoi
    else return token=tokenOnSymbolChar()

  nullToken = -> {type:tokenType=NULL, value:'', cursor:cursor, stopCursor:cursor, line:lineno, column:cursor-lineStart}
  setToken = (tkn) -> token = tkn; tokenType = token.type; token
  skipTokenType = (type) -> if tokenType==INDENT then nextToken()
  skipSPACE = -> (if tokenType==SPACE then nextToken()); token
  nextNonspaceToken = -> nextToken(); skipSPACE(); token
  skipSomeType = (types...) ->
    for t in types then if tokenType==t then nextToken(); return
    return

  rollbackOnType = (type, tkn) -> if tokenType==type then setToken(tkn)

  @tokenFnMap = tokenFnMap = {}

  tokenOnSymbolChar = ->
    cur = cursor
    while char = text[++cursor]
      if symbolStopChars[char] then break
      # //: line comment,  /!: regexp
      if char=='/' and ((c2=text[cursor+1])=='/' or c2=='!') then break

    token.next = {type:tokenType=SYMBOL, value: text.slice(cur, cursor),
    cursor:cur, stopCursor:cursor, line: lineno, column:cursor-lineStart}

  symbolStopChars = {}
  for c in ' \t\v\n\r()[]{},;:#\'\".@\\' then symbolStopChars[c] = true
  for c of firstIdentifierCharSet then symbolStopChars[c] = true
  for c in '0123456789' then symbolStopChars[c] = true

  tokenFnMap[':'] = tokenOnColonChar = ->
    cur = cursor; column = cursor-lineStart; first = char; char = text[++cursor]
    while char==first then char = text[++cursor]
    if cursor==cur+1 then tokenType = PUNCTUATION else tokenType = SYMBOL
    token.next = {type:tokenType, kind:SYMBOL, value: text.slice(cur, cursor), atom:cursor-cur==2
    cursor:cur, stopCursor:cursor, line: lineno, column:column}

  # token started with ' ' and '\t'
  tokenFnMap[' '] = tokenFnMap['\t'] = ->
    cur = cursor; line = lineno; column = cursor-lineStart; indent = lexIndent
    char = text[++cursor]
    skipInlineSpace(indent)
    if char
      if char!='\n' and char!='\r'
        token.next = {type:tokenType=SPACE, value:text[cur...cursor], cursor:cur, stopCursor: cursor,
        line:line, stopLine:lineno, column:column, indent:lexIndent}
      else
        newLineAndEmptyLines()
        token.next = {type:tokenType, value:text[cur...cursor], cursor:cur, line:line, column:column, indent:lexIndent}
    else
      token.next = {type:tokenType=EOI, value:text[cur...cursor], cursor:cur, line:line, column:column, indent:-1}

  # should be called after a new line
  skipSpaceLines = (dent) ->
    skipNewline()
    while 1
      if not char then return
      while char and char==' ' then cursor++; char = text[cursor]
      if char=='\t' then unexpectedTabCharAtLineHead()
      else if skipNewline() then continue
      else if not char then break
      else if (lexIndent=cursor-lineStart)!=dent then break
      else if char=='/' and (c2=text[cursor+1])=='/'
        cursor += 2; char = text[cursor]
        # skip line tail
        while (char=text[cursor]) and char!='\n' and char!='\r' then cursor++; char = text[cursor]
      else break
    return

  # skipInlineSpace is called by tokenOnSpaceChar
  # skiptInlineSpace should not generate independent token and called independently
  skipInlineSpace = ->
    while 1
      while char==' ' or char=='\t' then char = text[++cursor]
      if char=='/' and text[cursor+1]=='/'
        # don't need to process column here, because want to skip characters until reaching new line
        cursor += 2; char = text[cursor]
        while char!='\n' and char!='\r' then char = text[++cursor]; continue
        break
      break

  # \n\r, \r\n, \r, \n, don't eat spaces.
  skipNewline = ->
    if (c=char)=='\r'
      cursor++;
      if (c2=text[cursor])=='\n' then cursor++; c2 = '\n'
      char = text[cursor]; lineno++; lineStart = cursor
    else if char=='\n'
      cursor++
      if (c2=text[cursor])=='\r' then cursor++; c2 = '\r'
      char = text[cursor]; lineno++; lineStart = cursor
    else return
    c+(c2 or '')

  tokenOnNumberChar = ->

  isNewlineChar = (c) -> c== '\n' or c=='\r'

  leftRegexp = ->
    while char
      if char=='\\'
        if (c2=text[cursor+1]=='/') or c2=='\\' then cursor += 2; char = text[cursor]
        else char = text[cursor++]
      else if isNewlineChar(char)
        parseError 'meet unexpected new line while parsing regular expression'
      else if char=='/'
        i = 0; char = text[++cursor]
        # console.log text.slice(cursor)
        while char
          if char=='i' or char=='g'or char=='m' then char = text[++cursor]; ++i
          else break
          if i>3 then parseError 'too many modifiers "igm" after regexp'
        return
      else char = text[++cursor]
    if not char then parseError 'unexpected end of input while parsing regexp'

  # back slash \ can be used to escape keyword, conjunction, symbol
  tokenFnMap['\\'] = tokenOnBackSlashChar = ->
    cur = cursor; column = cursor-lineStart; char = text[++cursor]
    line = lineno
    if firstIdentifierCharSet[char]
      tkn = tokenOnIdentifierChar()
      tkn.type = tokenType = IDENTIFIER
      tkn.escaped = true; tkn.cursor = cur
      tkn.atom = true
      return token.next = tkn
    else if firstSymbolCharset[char]
      tkn = tokenOnSymbolChar()
      tkn.escaped = true; tkn.cursor = cur; token.value = '\\'+token.value
      return token.next = tkn
    else if char==':'
      tkn = tokenOnColonChar()
      tkn.value = '\\'+tkn.value; token.type = tokenType = SYMBOL
      tkn.escaped = true; tkn.cursor = cur
      return token.next = tkn
    else if char=="'"
      tkn = tokenOnQuoteChar()
      if text[cur+2]=="'" and text[cur+3]=="'"
        # do not escape '''...'''
        char = text[++cursor]
        return token.next = {type:tokenType=SYMBOL, value:'\\', cursor:cur, stopCursor:cursor
        line:lineno, column:cur-lineStart, indent:lexIndent
        next:tkn}
      else
        for c in text[cur+2...tkn.stopCursor]
          if c=='\n' or c=='\r' then parseError 'unexpected new line characters in escaped string'
        tkn.escaped = true; tkn.cursor = cur; tkn.atom = true
        return token.next = tkn
    # else if char=='"' # don't permit escape interpolated string
    else
      while char=text[++cursor]=='\\' then true
      return token.next = {type:tokenType=SYMBOL, kind:SYMBOL, value:text[cur...cursor], cursor:cur, stopCursor:cursor
      line:lineno, column:cur-lineStart}

  tokenFnMap['/'] = tokenOnForwardSlashChar = ->
    cur = cursor; column = cursor-lineStart; char = text[++cursor]; line = lineno; indent = lexIndent
    # // start a line comment
    if char=='/' # // leading line comment
      # skip line tail
      cursor++; char=text[cursor]
      while char and char!='\n' and char!='\r' then cursor++; char=text[cursor]
      if char
        if char!='\n' and char!='\r'
          token.next = {type:tokenType=SPACE, value: text[cur...cursor], cursor:cur, stopCursor:cursor, line:line, stopLine:lineno, column:column, indent:lexIndent}
        else
          newLineAndEmptyLines()
          token.next = {type:tokenType, value: text[cur...cursor], cursor:cur, stopCursor:cursor, line:line, column:column, indent:lexIndent}
      else
        token.next = {type:tokenType=EOI, value: text[cur...cursor], cursor:cur, stopCursor:cursor, line:line, column:column, indent:lexIndent}
    # /! start a regexp
    else if char=='!'
      cur = cursor; cursor += 2; char = text[cursor]; column = cursor-lineStart
      leftRegexp()
      return token.next = {type:tokenType=REGEXP, value:['regexp!', '/'+text[cur+1...cursor]], atom:true, cursor:cur, stopCursor:cursor, line:lineno, column: column}
    else
      # a symbol starts with "/"
      char = text[++cursor]; prev = token; tokenOnSymbolChar(); value = "/"+token.value
      token = {type:tokenType=SYMBOL, value:value, cursor:cur, stopCursor:cursor, line:line, column:column}
      return prev.next = token

  newLineAndEmptyLines = ->
    while 1
      if char=='\n'
        char = text[++cursor]
        if char=='\r' then char = text[++cursor]
        lineStart = cursor
        while char and char==' ' then char = text[++cursor]
        if char=='\t' then parseError 'unexpected tab character "\t" at the head of line'
        if not char or (char!='\n' and char!='\r') then break
      else if char=='\r'
        char = text[++cursor]
        if char=='\n' then char = text[++cursor]
        lineStart = cursor
        while char and char==' ' then char = text[++cursor]
        if char=='\t' then parseError 'unexpected tab character "\t" at the head of line'
        if not char or (char!='\n' and char!='\r') then break
      else break
    if not char then type = EOI; lexIndent = -1
    else
      lexIndent = cursor-lineStart
      if lexIndent>indent then tokenType = INDENT
      else if lexIndent<indent then tokenType = UNDENT
      else tokenType = NEWLINE

  # the token leaded by '\n', '\r', maybe return token with type NEWLINE, INDENT, UNDENT, EOI
  tokenFnMap['\n'] = tokenFnMap['\r'] = tokenOnNewlineChar = ->
    cur = cursor; line = lineno; column = cursor-lineStart; indent = lexIndent
    newLineAndEmptyLines()
    return token.next = {type:tokenType, value:text[cur...cursor],
    cursor:cur, stopCursor:cursor,
    line:line, column:column, indent:lexIndent}

  identifierCharSet = taijiIdentifierCharSet

  tokenOnIdentifierChar = ->
    cur = cursor; char = text[++cursor]; column = cursor-lineStart
    while char and identifierCharSet[char] then char=text[++cursor]
    if char=='=' and text[cursor-1]=='!' then char = text[--cursor]
    txt = text.slice(cur, cursor)
    if keywordHasOwnProperty(txt) then tokenType = KEYWORD; isAtom = false
    else if conjunctionHasOwnProperty(txt) then tokenType = CONJUNCTION; isAtom = false
    else tokenType = IDENTIFIER; isAtom = true
    token.next = {type:tokenType, kind:SYMBOL, transformed:true, value:txt, atom:isAtom
    cursor:cur, stopCursor: cursor,
    line: lineno, column: column}

  for c of firstIdentifierCharSet then tokenFnMap[c] = tokenOnIdentifierChar

  for c in '0123456789' then tokenFnMap[c] = tokenOnNumberChar

  tokenFnMap[','] = tokenFnMap[';'] = ->
    cur = cursor; char = text[++cursor]
    token.next = {type:tokenType=PUNCTUATION, kind:SYMBOL, value:',', line:lineno, cursor:cursor, stopCursor:cursor, column: cur-lineStart}

  tokenFnMap["'"] = tokenFnMap['"'] = tokenOnQuoteChar = ->
    quote = char; char = text[++cursor]; column = cursor-lineStart
    if char==quote
      if text[cursor+1]==quote
        char = text[++cursor]
        return token.next = {value:'""', type:tokenType=STRING, atom:true, cursor:cursor-2, line:lineno, column:column, atom:true}
    else
      cur = cursor-1; line = lineno; column = cur-lineStart
      if cursor==indent+1 then indentInfo = {value:indent}
      else indentInfo = {}
      s = ''
      # the left characters of the same line after '''
      while char
        if char==quote
          char = text[++cursor]
          return token.next = {type:tokenType=STRING, value: '"'+s+'"', atom:true, cursor:cur, stopCursor:cursor, line:line, stopLine:lineno, column:column}
        else if char=='\\'
          char = text[++cursor]
          if isNewlineChar(char) then error 'unexpected new line while parsing string'
          char = text[++cursor]
        else if isNewlineChar(char) then error 'unexpected new line while parsing string'
      parseError "expect \"'\", unexpected end of input while parsing interpolated string"

  # for efficiency, in tokenOnLeftParenChar, tokenOnLeftBracketChar, tokenOnLeftCurveChar
  # do not match next token while matching delimiter token (...), [...], {...}
  tokenFnMap['('] = tokenOnLeftParenChar = ->
    cur = cursor; line = lineno; column = cursor-lineStart; char = text[++cursor] # skip "("
    prev = token; matchToken()
    if tokenType==UNDENT then parseError 'unexpected undent while parsing parenethis "(...)"'
    ind = indent = lexIndent
    if tokenType==SPACE or tokenType==NEWLINE or tokenType==INDENT then nextToken()
    if token.value==')'
      return prev.next = token = extend ['()'], {type:tokenType=PAREN
      atom:true, cursor:cur, stopCursor: cursor,
      line:lineno, column:column, indent:lexIndent, empty:true, parameters:true}
    exp = parser.operatorExpression()
    if tokenType==UNDENT
      if token.indent<ind then parseError 'expect ) indent equal to or more than ('
      else nextToken()
    else
      skipSPACE()
      if token.value!=')' then parseError 'expect )'
    # To make interpolated string happy, we can not call nextToken() here
    #else nextToken() # do not match token here, so token.next==undefined, and nextToken() will matchToken instead.
    return prev.next = token = extend ['()', exp], {
    type:tokenType=PAREN, cursor:cur, stopCursor:cursor
    line:line, column:column, indent:lexIndent, atom:true, parameters:true}

  tokenFnMap['['] = tokenOnLeftBracketChar = ->
    trace "tokenFnMap['[']: ",  nextPiece()
    cur = cursor; char = text[++cursor]; line = lineno; column = cursor-lineStart
    prev = token; matchToken()
    exp = parser.block() or parser.lineBlock()
    if tokenType==UNDENT
      if token.indent<ind then parseError 'unexpected undent while parsing parenethis "[...]"'
      else nextToken()
    if token.value!=']' then parseError 'expect ]'
    # To make interpolated string happy, we can not call nextToken() here
    # so that token.next==undefined, and nextToken() will matchToken instead.
    # tkn = nextToken()
    if not exp then value = ['[]']
    else value = [('[]'), exp]
    return prev.next = token = extend value, {type:tokenType=BRACKET, cursor:cur, stopCursor:cursor
    line:line, column:column, indent:lexIndent, atom:true}

  tokenFnMap['{'] = ->
    trace "tokenFnMap['{']: " +nextPiece()
    cur = cursor; char = text[++cursor]; line = lineno; column = cursor-lineStart; ind = lexIndent
    prev = token; matchToken()
    skipSPACE()
    if token.value=='}' and tkn=nextToken()
      return prev.next = token = extend ['{}'],  {kind:LIST, atom:true, cursor:cur, stopCursor:cursor
      line:line, column:column, indent:lexIndent, next:tkn}
    body = parser.block() or parser.lineBlock()
    if tokenType==UNDENT and token.indent<ind then nextToken()
    if token.value!='}' then parseError 'expect }'
    tkn = nextToken()
    # To make interpolated string happy, we can not call nextToken() here
    if indent<ind then parseError 'unexpected undent while parsing parenethis "{...}"'
    prev.next = token = extend ['{}', begin(body)], {
    type:tokenType=CURVE, atom:true, cursor:cur, stopCursor:cursor
    line:line, column:column, indent:lexIndent, next:tkn}

  tokenOnRightDelimiterChar = ->
    c = char; cur = cursor; char = text[++cursor]
    token.next = {type:tokenType=RIGHT_DELIMITER, value:c, cursor:cur, stopCursor:cursor,
    line:lineno, column:cur-lineStart}

  for c in ')]}' then tokenFnMap[c] = tokenOnRightDelimiterChar

  # prefix operator don't need to be compared to current global priority
  @prefixOperator = (mode) ->
    # hasOwnProperty.call is necessary in order to avoid error while builtin attribute of object is defined prefix operator
    tokenText = token.value
    if not hasOwnProperty.call(prefixOperatorDict, tokenText) or  not (op=prefixOperatorDict[tokenText]) then return
    if (mode==COMPACT_CLAUSE_EXPRESSION or mode==SPACE_CLAUSE_EXPRESSION) and op.definition then return
    opToken = token; nextToken()
    if tokenType==INDENT or tokenType==NEWLINE or tokenType==UNDENT
      if mode==COMPACT_CLAUSE_EXPRESSION then token = opToken; tokenType = opToken.type; return
      else nextToken()
    else if tokenType==RIGHT_DELIMITER
      if mode!=COMPACT_CLAUSE_EXPRESSION then error 'unexpected '+token.value
      else opToken.atom = true; return opToken
    {value:opToken.value, kind:SYMBOL, transformed:true, start:opToken, stop:token, priority:op.priority+priInc}

  @binaryOperator = (mode) ->
    start = token
    if tokenType==SPACE
      if mode== COMPACT_CLAUSE_EXPRESSION then return
      else nextToken()
    if tokenType!=IDENTIFIER and tokenType!=SYMBOL
      if mode==COMPACT_CLAUSE_EXPRESSION then return
      else if tokenType==RIGHT_DELIMITER then error 'unexpected '+token.value
      else if tokenType==EOI then error 'unexpected end of input'
      else if tokenType==UNDENT and indent<dent then 'wrong undent'

    if not hasOwnProperty.call(binaryOperatorDict, opValue)
      start[binaryOperatorMemoIndex+mode] = {}
      token = start; tokenType = token.type;  return
    op = binaryOperatorDict[opValue]

    {value:opValue, priority:op.priority, rightAssoc:rightAssoc, assign:op.assign}

  @prefixExpression = (mode, priority) ->
    start = token
    # current global prority doesn't affect prefixOperator
    if op=parser.prefixOperator(mode)
      pri = if priority>op.priority then priority else op.priority
      x = parser.expression(mode, pri, true)
      if x
        return extend ['prefix!', op.value, x], {
        expressionType:PREFIX, priority:op.priority, rightAssoc:op.rightAssoc, start:op.start, stop:(op.stop or op.start)}
      else token = start; tokenType = token.type;  return

  @expression = expression = (mode, priority, leftAssoc) ->
    # add non digit prefix is necessary, else array will become sparse array
    start = token
    if not x = parser.prefixExpression(mode, priority)
      if not token.atom then return
      else x = token; x.priority = 1000; nextToken()
    # the priority and association of suffix operator does not affect the following expression
    while 1
      tkn2 = token
      if (op=parser.binaryOperator(mode, x))
        if (opPri=op.priority)>priority  or (opPri==priority and not leftAssoc)
          # should assure that a right operand is here while parsing binary operator
          y = expression(mode, opPri, not op.rightAssoc)
          if y
            x = extend ['binary!', op.value, x, y], {
            expressionType:BINARY, priority:op.priority, rightAssoc:op.rightAssoc
            start:op.start, stop:(op.stop or op.start)}
          else token = tkn2; tokenType = token.type;  break
        else token = tkn2; tokenType = token.type;  break
      else break
    x

  # the priority of operator vary from 0 to 300,
  # if there is no space between them, then add 600, if there is spaces, then add 300.
  # if meet newline, add 0.
  @operatorExpression = operatorExpression = -> parser.expression(OPERATOR_EXPRESSION, 0, true)

  # compact expression as clause item.
  @compactClauseExpression = -> parser.expression(COMPACT_CLAUSE_EXPRESSION, 600, true)

  expectThen = (isHeadStatement, clauseIndent) ->
    skipSPACE()
    if atStatementHead and not isHeadStatement then parseError 'unexpected new line before "then" of inline keyword statement'
    if tokenType==INDENT then parseError 'unexpected indent before "then"'
    else if tokenType==EOI
      parseError 'unexpected end of input, expect "then"'
    if tokenType==NEWLINE then nextToken()
    else if tokenType==UNDENT and token.indent>=clauseIndent then nextToken()
    if atStatementHead and indent!=clauseIndent then parseError 'wrong indent before "then"'
    if tokenType==CONJUNCTION
      if token.value=="then" then nextToken(); return true
      else parseError 'unexpected conjunction "'+token.value+'", expect "then"'
    else parseError 'expect "then"'

  maybeConjunction = (conj, isHeadStatement, clauseIndent) ->
    if atStatementHead and not isHeadStatement then return
    if tokenType==EOI then return
    if indent<clauseIndent then return
    if indent>clauseIndent then parseError 'wrong indent'
    if indent==clauseIndent and tokenType==CONJUNCTION and token.value==conj
      conj = token; nextToken(); return conj

  # if test then action else action
  keywordThenElseStatement = (keyword) -> (isHeadStatement) ->
    ind = indent; nextNonspaceToken()
    if not (test=parser.clause()) then parseError 'expect a clause after "'+keyword+'"'
    expectThen(isHeadStatement, ind)
    then_ = parser.block() or parser.line()
    if tokenType==NEWLINE then tkn = token; nextToken()
    if maybeConjunction('else', isHeadStatement, ind)
      else_ = parser.block() or parser.line()
    else if tkn then token = tkn; tokenType = token.type
    if else_ then [keyword, test, begin(then_), begin(else_)]
    else [keyword, test, begin(then_)]

  # throw or return value
  throwReturnStatement = (keyword) -> (isHeadStatement) ->
    nextNonspaceToken()
    if clause = parser.clause() then [keyword, clause]
    else [keyword]

  # break; continue
  breakContinueStatement = (keyword) -> (isHeadStatement) ->
    nextNonspaceToken()
    if tokenType==IDENTIFIER
      label = token; nextNonspaceToken()
      [keyword, label]
    else skipSPACE(); [keyword]

  @keyword2statement = keyword2statement =

    'break': breakContinueStatement('break')
    'continue': breakContinueStatement('continue')
    'throw': throwReturnStatement('throw')
    'return': throwReturnStatement('return')
    'new': throwReturnStatement('new')

    'if': keywordThenElseStatement('if')
    'while': keywordThenElseStatement('while')

    'for': (isHeadStatement) ->
      ind = indent; matchToken()
      skipSPACE()
      if tokenType!=IDENTIFIER then parseError 'expect identifier'
      name1 = token
      nextToken()
      skipSPACE()
      if token.value==',' # optional ","
        nextNonspaceToken()
      if tokenType!=IDENTIFIER then parseError 'expect "in", "of" or index variable name'
      if (value=token.value)=='in' or value=='of' then inOf = value; nextToken()
      else
        name2 = token; nextNonspaceToken()
        if (value=token.value)=='in' or value=='of' then inOf = value; nextToken()
        else  'expect "in" or "of"'
      skipSPACE()
      obj = parser.clause()
      expectThen(isHeadStatement, ind)
      body = parser.block() or parser.line()
      if inOf=='in' then kw = 'forIn!' else kw = 'forOf!'
      [kw, name1, name2, obj, begin(body)]

    'try': (isHeadStatement) ->
      ind = indent; nextToken(); # skip "try"
      skipSPACE()
      if not (test = parser.block() or parser.line()) then parseError 'expect a line or block after "try"'
      if atStatementHead and not isHeadStatement
        parseError 'meet unexpected new line when parsing inline try statement'
      if maybeConjunction("catch", isHeadStatement, ind)
        skipSPACE(); atStatementHead = false
        if tokenType==IDENTIFIER
          catchVar = token; nextToken()
        skipSPACE()
        if tokenType!=CONJUNCTION or token.value!='then'
          parseError('expect "then" after "catch +'+catchVar.value+'"')
        nextNonspaceToken()
        catch_ = parser.block() or parser.line()
      if maybeConjunction("finally", isHeadStatement, ind)
        skipSPACE()
        final = parser.block() or parser.line()
        ['try', test, catchVar, begin(catch_)]
      else ['try', begin(test), catchVar, begin(catch_), begin(final)]

  @sequenceClause = ->
    clause = []
    while 1
      skipSPACE(); tkn = token
      if (item=parser.compactClauseExpression())
        if item.value=='#' then token = tkn; tokenType = token.type; break
        else clause.push item
      else break
    if not clause.length then return
    clause

  leadWordClauseMap = {}

  # preprocess opertator #, see metaConvertFnMap['#'] and preprocessMetaConvertFnMap for more information
  # evaluate in compile time ##, see metaConvertFnMap['##']
  # evaluate in both compile time and run time #/, see metaConvertFnMap['#/']
  # escape from compile time to runtime #-, see metaConvertFnMap['#-']
  # #&: metaConvert exp and get the current expression(not metaConverted raw program), see metaConvertFnMap['#&']

  for sym in ['~', '`', '^', '^&', '#', '##', '#/', '#-', '#&'] then leadWordClauseMap[sym] = (tkn, clause) ->  [tkn, clause]

  leadTokenClause = (fn) -> ->
    start = token
    if (type=nextToken().type)!=SPACE and type!=INDENT then token = start; tokenType = token.type;  return
    nextToken()
    if not (fn=leadWordClauseMap[start.value]) then token = start; tokenType = token.type;  return
    fn(start, parser.clause())

  for key, fn of leadWordClauseMap then symbol2clause[key] = leadTokenClause(fn)

  @definitionSymbolBody = definitionSymbolBody = ->
    start = token; nextNonspaceToken()
    if tokenType==INDENT then body = parser.block()
    else body = parser.line()
    [start, [], begin(body)]

  symbol2clause['->'] = symbol2clause['=>'] = definitionSymbolBody

  nextPiece = ->
    if not char then 'end of input'
    else text[cursor...(cursor+8>textLength? textLength: cursor+8)]

  @clause = ->
    trace("clause: "+nextPiece())
    skipSPACE(); start = token
    switch tokenType
      when KEYWORD
        isStatementHead = atStatementHead
        atStatementHead = false
        return keyword2statement[token.value](isStatementHead)
      when SYMBOL
        if (fn=symbol2clause[token.value]) and (result = fn()) then return result
      when NEWLINE, UNDENT, RIGHT_DELIMITER, CONJUNCTION, EOI then return

    if clause = parser.sequenceClause() then clause.value.unshift head
    else clause = head

    if (op=binaryOperatorDict[token.value]) and op.definition
      definition = definitionSymbolBody()
      if clause.parameters
        definition.value[1] = clause; clause = definition; definition.start = start
      else if (clauseValue=clause.value) instanceof Array and clauseValue.length>1
          params = clauseValue[clauseValue.length-1]
          if params.parameters
            clauseValue.pop()
            definition[1] = params
            definition.start = params.start
          clauseValue.push definition
      else clause = {value:[clause, definition]}
      return clause

    if (value=token.value)==',' then nextToken(); clause

    else if value==':'
      nextToken()
      if tokenType==INDENT then clauses = parser.block()
      else clauses = parser.clauses()
      if clauses.length==0 then parseError 'expected arguments list after ":"'
      # notice the different between only indent
      clauses.unshift clause
      return clauses

    else if token.value=='#' and nextToken()
      if tokenType==SPACE then clauses = parser.clauses(); return ['#', clause, clauses]
      else if tokenType==INDENT then clauses = parser.block(); return ['#', clause, clauses]

    else if tokenType==INDENT
      tkn = token; nextToken()
      if tokenType==CONJUNCTION then setToken(tkn); atStatementHead = true; return clause
      else
        token = tkn; tokenType = token.type;  atStatementHead = true
        # head clause with indented block
        blk = parser.block()
        if (clauseValue=clause.value) instanceof Array then clauseValue.push.apply clauseValue, blk; clause.stop = token; return clause
        else blk.unshift clause; return {value:blk}

    else clause

  @clauses = ->
    result = []; tkn = token
    while clause=parser.clause()
      result.push clause
      if tkn==token then parseError 'oops! inifinte loops!!!'
      tkn = token;
    return result

  @sentence = ->
    if tokenType==EOI or tokenType==INDENT or tokenType==UNDENT or tokenType==NEWLINE or tokenType==RIGHT_DELIMITER or tokenType==CONJUNCTION then return
    result = parser.clauses()
    if token.value==';' and nextToken() then skipTokenType SPACE
    result

  @line = ->
    if tokenType==UNDENT or tokenType==RIGHT_DELIMITER or tokenType==CONJUNCTION or tokenType==EOI then return
    if tokenType==INDENT then return parser.block(indent)
    result = []; tkn = token
    while x=parser.sentence()
      result.push.apply result, x
      if tkn==token then parseError 'oops! inifinte loops!!!'
      tkn = token
    result

  @block = (dent) -> skipTokenType INDENT; return parser.blockWithoutIndentHead(indent)

  # a block with out indent( the indent has been ate before).
  # stop until meet a undent (less indent than the intent of the start line)
  @blockWithoutIndentHead = (dent) ->
    result = []; ind = indent
    while (x=parser.line())
      result.push.apply result, x
      if tokenType==NEWLINE then nextToken(); continue
      if tokenType==EOI then break
      else if tokenType==UNDENT
        if indent<dent then break
        else if indent==dent then nextToken(); break
        else if indent==ind then nextToken(); continue
        else parseError 'wrong indent'
      else if tokenType==CONJUNCTION then parseError 'unexpected conjunction "'+token.value+'" following a indent block'
    return result

  @lineBlock = (dent) ->
    result = parser.line()
    skipSomeType(NEWLINE, SPACE); tkn = token
    skipTokenType(INDENT); rollbackOnType(CONJUNCTION, tkn)
    if tokenType==CONJUNCTION then setToken(tkn)
    else
      setToken(tkn)
      if token.indent>dent then result.push.apply result, parser.blockWithoutIndentHead()
    result

  @module = ->
    nextToken(); body = []
    while 1
      if not x=parser.line() then break
      skipTokenType NEWLINE
      body.push.apply body, x
    if tokenType!=EOI then parseError 'expect end of input, but meet "'+text.slice(cursor)+'"'
    begin(body)

  @parse = (data, root, cur) ->
    text = data; textLength = text.length
    cursor = cur; char = text[cursor]; lineno = 1; lineStart = 0
    token = nullToken; atStatementHead = true
    root()

  parseError = (message, tkn) ->
    tkn = tkn or token; cur = token.cursor
    throw cur+'('+tkn.line+':'+tkn.column+'): '+message+': '+text[tkn.cursor...tkn.stopCursor]

  return

exports.Parser.name = 'Parser'